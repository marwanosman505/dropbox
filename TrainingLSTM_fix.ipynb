{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marwanosman505/dropbox/blob/main/TrainingLSTM_fix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wHVWuQ4byieo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef35de6-c28d-40d3-9bbc-18e7ae381570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n",
            "--2023-10-13 11:08:04--  https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76120962 (73M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py38_4.1 100%[===================>]  72.59M   222MB/s    in 0.3s    \n",
            "\n",
            "2023-10-13 11:08:05 (222 MB/s) - ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’ saved [76120962/76120962]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py38h06a4308_2\n",
            "    - cffi==1.15.0=py38hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py38h7f8727e_0\n",
            "    - conda==4.12.0=py38h06a4308_0\n",
            "    - cryptography==36.0.0=py38h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.13=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py38h27cfd23_0\n",
            "    - setuptools==61.2.0=py38h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py38h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py38hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py38h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py38h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py38h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.13-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py38h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py38h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 23.9.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
            "    certifi-2023.7.22          |   py38h06a4308_0         153 KB\n",
            "    cffi-1.15.1                |   py38h5eee18b_3         241 KB\n",
            "    conda-package-handling-2.2.0|   py38h06a4308_0         267 KB\n",
            "    conda-package-streaming-0.9.0|   py38h06a4308_0          27 KB\n",
            "    cryptography-41.0.3        |   py38hdda0065_0         2.0 MB\n",
            "    idna-3.4                   |   py38h06a4308_0          93 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n",
            "    libffi-3.4.4               |       h6a678d5_0         142 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ncurses-6.4                |       h6a678d5_0         914 KB\n",
            "    openssl-3.0.11             |       h7f8727e_2         5.2 MB\n",
            "    pip-23.2.1                 |   py38h06a4308_0         2.6 MB\n",
            "    pycosat-0.6.6              |   py38h5eee18b_0          93 KB\n",
            "    pyopenssl-23.2.0           |   py38h06a4308_0          96 KB\n",
            "    python-3.8.18              |       h955ad1f_0        25.3 MB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    requests-2.31.0            |   py38h06a4308_0          96 KB\n",
            "    setuptools-68.0.0          |   py38h06a4308_0         927 KB\n",
            "    sqlite-3.41.2              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.0 MB\n",
            "    urllib3-1.26.16            |   py38h06a4308_0         200 KB\n",
            "    wheel-0.41.2               |   py38h06a4308_0         108 KB\n",
            "    xz-5.4.2                   |       h5eee18b_0         642 KB\n",
            "    zlib-1.2.13                |       h5eee18b_0         103 KB\n",
            "    zstandard-0.19.0           |   py38h5eee18b_0         474 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        55.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  conda-package-str~ pkgs/main/linux-64::conda-package-streaming-0.9.0-py38h06a4308_0\n",
            "  zstandard          pkgs/main/linux-64::zstandard-0.19.0-py38h5eee18b_0\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  six-1.16.0-pyhd3eb1b0_1\n",
            "  tqdm-4.63.0-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu\n",
            "  ca-certificates                      2022.3.29-h06a4308_1 --> 2023.08.22-h06a4308_0\n",
            "  certifi                          2021.10.8-py38h06a4308_2 --> 2023.7.22-py38h06a4308_0\n",
            "  cffi                                1.15.0-py38hd667e15_1 --> 1.15.1-py38h5eee18b_3\n",
            "  conda-package-han~                   1.8.1-py38h7f8727e_0 --> 2.2.0-py38h06a4308_0\n",
            "  cryptography                        36.0.0-py38h9ce1e76_0 --> 41.0.3-py38hdda0065_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0~ --> pkgs/main/linux-64::idna-3.4-py38h06a4308_0\n",
            "  ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.38-h1181459_1\n",
            "  libffi                                     3.3-he6710b0_2 --> 3.4.4-h6a678d5_0\n",
            "  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.4-h6a678d5_0\n",
            "  openssl                                 1.1.1n-h7f8727e_0 --> 3.0.11-h7f8727e_2\n",
            "  pip                                 21.2.4-py38h06a4308_0 --> 23.2.1-py38h06a4308_0\n",
            "  pycosat                              0.6.3-py38h7b6447c_1 --> 0.6.6-py38h5eee18b_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-py~ --> pkgs/main/linux-64::pyopenssl-23.2.0-py38h06a4308_0\n",
            "  python                                  3.8.13-h12debd9_0 --> 3.8.18-h955ad1f_0\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyh~ --> pkgs/main/linux-64::requests-2.31.0-py38h06a4308_0\n",
            "  setuptools                          61.2.0-py38h06a4308_0 --> 68.0.0-py38h06a4308_0\n",
            "  sqlite                                  3.38.2-hc218d9a_0 --> 3.41.2-h5eee18b_0\n",
            "  tk                                      8.6.11-h1ccaba5_0 --> 8.6.12-h1ccaba5_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd~ --> pkgs/main/linux-64::urllib3-1.26.16-py38h06a4308_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3e~ --> pkgs/main/linux-64::wheel-0.41.2-py38h06a4308_0\n",
            "  xz                                       5.2.5-h7b6447c_0 --> 5.4.2-h5eee18b_0\n",
            "  zlib                                    1.2.12-h7f8727e_1 --> 1.2.13-h5eee18b_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pyopenssl-23.2.0     | 96 KB     | : 100% 1.0/1 [00:00<00:00,  4.82it/s]\n",
            "wheel-0.41.2         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  7.07it/s]\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00,  6.34it/s]\n",
            "xz-5.4.2             | 642 KB    | : 100% 1.0/1 [00:00<00:00,  6.13it/s]\n",
            "certifi-2023.7.22    | 153 KB    | : 100% 1.0/1 [00:00<00:00,  7.39it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  4.13it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  7.35it/s]\n",
            "zstandard-0.19.0     | 474 KB    | : 100% 1.0/1 [00:00<00:00,  6.88it/s]\n",
            "urllib3-1.26.16      | 200 KB    | : 100% 1.0/1 [00:00<00:00,  7.33it/s]\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:00<00:00,  7.59it/s]\n",
            "python-3.8.18        | 25.3 MB   | : 100% 1.0/1 [00:00<00:00,  1.39it/s]\n",
            "tk-8.6.12            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.40it/s]\n",
            "conda-package-handli | 267 KB    | : 100% 1.0/1 [00:00<00:00,  7.31it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00,  6.98it/s]\n",
            "idna-3.4             | 93 KB     | : 100% 1.0/1 [00:00<00:00,  7.21it/s]\n",
            "sqlite-3.41.2        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  6.65it/s]\n",
            "pip-23.2.1           | 2.6 MB    | : 100% 1.0/1 [00:00<00:00,  3.45it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.82it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  6.86it/s]\n",
            "conda-package-stream | 27 KB     | : 100% 1.0/1 [00:00<00:00,  7.58it/s]\n",
            "setuptools-68.0.0    | 927 KB    | : 100% 1.0/1 [00:02<00:00,  2.03s/it]\n",
            "ca-certificates-2023 | 123 KB    | : 100% 1.0/1 [00:00<00:00,  7.39it/s]\n",
            "cffi-1.15.1          | 241 KB    | : 100% 1.0/1 [00:00<00:00,  7.18it/s]\n",
            "libffi-3.4.4         | 142 KB    | : 100% 1.0/1 [00:00<00:00,  6.36it/s]\n",
            "requests-2.31.0      | 96 KB     | : 100% 1.0/1 [00:00<00:00,  7.27it/s]\n",
            "openssl-3.0.11       | 5.2 MB    | : 100% 1.0/1 [00:00<00:00,  4.37it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  3.02it/s]\n",
            "zlib-1.2.13          | 103 KB    | : 100% 1.0/1 [00:00<00:00,  6.90it/s]\n",
            "cryptography-41.0.3  | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.10it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 23.9.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        39.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.08.22-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1\n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.4.2-h5eee18b_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  3.86it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  7.41it/s]\n",
            "python-3.6.13        | 32.5 MB   | : 100% 1.0/1 [00:04<00:00,  4.67s/it]              \n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00, 25.30it/s]\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.71it/s]\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "!conda create -n myenv python=3.6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "git clone https://github.com/ml5js/training-charRNN\n",
        "pip install -r training-charRNN/requirements.txt\n",
        "wget https://raw.githubusercontent.com/marwanosman505/dropbox/main/paulocoelho.txt\n",
        "python3 training-charRNN/train.py --data_path paulocoelho.txt \\\n",
        "--rnn_size 128 \\\n",
        "--num_layers 2 \\\n",
        "--seq_length 50 \\\n",
        "--batch_size 50 \\\n",
        "--num_epochs 2 \\\n",
        "--save_checkpoints ./checkpoints \\\n",
        "--save_model ./models\n",
        "zip -r model.zip models/paulocoelho"
      ],
      "metadata": {
        "id": "6vokE3BvzJqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22eedd2-5f10-46a4-9566-775c16c5cfa4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'training-charRNN'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 105 (delta 31), reused 28 (delta 28), pack-reused 68\u001b[K\n",
            "Receiving objects: 100% (105/105), 33.50 KiB | 1.29 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Collecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 81 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 64.6 MB/s \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 22 kB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.4->-r training-charRNN/requirements.txt (line 1)) (0.37.1)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 68.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 58.2 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 60.9 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r training-charRNN/requirements.txt (line 1)) (58.0.4)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: gast, termcolor\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=085e2145f115c4742ad1aa2026073501d44307b8627b95b7d42e7be787155357\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=a4d3863b7377be7680b1d9575638e0757b63d5e8c131afd508e7d789611c7c7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built gast termcolor\n",
            "Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, dataclasses, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "Successfully installed absl-py-1.4.0 astor-0.8.1 cached-property-1.5.2 dataclasses-0.8 gast-0.2.2 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.19.6 six-1.16.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 termcolor-1.1.0 typing-extensions-4.1.1 werkzeug-2.0.3 wrapt-1.15.0 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "--2023-10-13 11:12:25--  https://raw.githubusercontent.com/marwanosman505/dropbox/main/paulocoelho.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 812505 (793K) [text/plain]\n",
            "Saving to: ‘paulocoelho.txt’\n",
            "\n",
            "paulocoelho.txt     100%[===================>] 793.46K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-13 11:12:25 (13.7 MB/s) - ‘paulocoelho.txt’ saved [812505/812505]\n",
            "\n",
            "WARNING:tensorflow:From training-charRNN/train.py:29: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From training-charRNN/train.py:29: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n",
            "Here we go! Reading text file...\n",
            "0/638 (epoch 0), train_loss = 4.464, time/batch = 0.700\n",
            "Model saved to ./checkpoints/paulocoelho/paulocoelho!\n",
            "1/638 (epoch 0), train_loss = 4.422, time/batch = 0.160\n",
            "2/638 (epoch 0), train_loss = 4.330, time/batch = 0.144\n",
            "3/638 (epoch 0), train_loss = 4.051, time/batch = 0.155\n",
            "4/638 (epoch 0), train_loss = 3.598, time/batch = 0.154\n",
            "5/638 (epoch 0), train_loss = 3.436, time/batch = 0.147\n",
            "6/638 (epoch 0), train_loss = 3.390, time/batch = 0.135\n",
            "7/638 (epoch 0), train_loss = 3.281, time/batch = 0.155\n",
            "8/638 (epoch 0), train_loss = 3.253, time/batch = 0.153\n",
            "9/638 (epoch 0), train_loss = 3.192, time/batch = 0.154\n",
            "10/638 (epoch 0), train_loss = 3.118, time/batch = 0.141\n",
            "11/638 (epoch 0), train_loss = 3.124, time/batch = 0.157\n",
            "12/638 (epoch 0), train_loss = 3.172, time/batch = 0.148\n",
            "13/638 (epoch 0), train_loss = 3.133, time/batch = 0.152\n",
            "14/638 (epoch 0), train_loss = 3.237, time/batch = 0.147\n",
            "15/638 (epoch 0), train_loss = 3.175, time/batch = 0.159\n",
            "16/638 (epoch 0), train_loss = 3.195, time/batch = 0.152\n",
            "17/638 (epoch 0), train_loss = 3.109, time/batch = 0.154\n",
            "18/638 (epoch 0), train_loss = 3.078, time/batch = 0.163\n",
            "19/638 (epoch 0), train_loss = 3.131, time/batch = 0.156\n",
            "20/638 (epoch 0), train_loss = 3.147, time/batch = 0.150\n",
            "21/638 (epoch 0), train_loss = 3.223, time/batch = 0.154\n",
            "22/638 (epoch 0), train_loss = 3.038, time/batch = 0.150\n",
            "23/638 (epoch 0), train_loss = 3.045, time/batch = 0.156\n",
            "24/638 (epoch 0), train_loss = 3.144, time/batch = 0.138\n",
            "25/638 (epoch 0), train_loss = 3.103, time/batch = 0.148\n",
            "26/638 (epoch 0), train_loss = 3.164, time/batch = 0.150\n",
            "27/638 (epoch 0), train_loss = 3.201, time/batch = 0.216\n",
            "28/638 (epoch 0), train_loss = 3.101, time/batch = 0.244\n",
            "29/638 (epoch 0), train_loss = 3.119, time/batch = 0.220\n",
            "30/638 (epoch 0), train_loss = 3.057, time/batch = 0.253\n",
            "31/638 (epoch 0), train_loss = 3.054, time/batch = 0.241\n",
            "32/638 (epoch 0), train_loss = 3.129, time/batch = 0.241\n",
            "33/638 (epoch 0), train_loss = 3.098, time/batch = 0.253\n",
            "34/638 (epoch 0), train_loss = 3.146, time/batch = 0.248\n",
            "35/638 (epoch 0), train_loss = 3.130, time/batch = 0.256\n",
            "36/638 (epoch 0), train_loss = 3.091, time/batch = 0.252\n",
            "37/638 (epoch 0), train_loss = 3.099, time/batch = 0.253\n",
            "38/638 (epoch 0), train_loss = 3.108, time/batch = 0.245\n",
            "39/638 (epoch 0), train_loss = 3.047, time/batch = 0.248\n",
            "40/638 (epoch 0), train_loss = 3.084, time/batch = 0.237\n",
            "41/638 (epoch 0), train_loss = 3.066, time/batch = 0.246\n",
            "42/638 (epoch 0), train_loss = 3.113, time/batch = 0.242\n",
            "43/638 (epoch 0), train_loss = 3.041, time/batch = 0.228\n",
            "44/638 (epoch 0), train_loss = 3.088, time/batch = 0.234\n",
            "45/638 (epoch 0), train_loss = 3.039, time/batch = 0.257\n",
            "46/638 (epoch 0), train_loss = 3.025, time/batch = 0.257\n",
            "47/638 (epoch 0), train_loss = 3.111, time/batch = 0.255\n",
            "48/638 (epoch 0), train_loss = 3.069, time/batch = 0.248\n",
            "49/638 (epoch 0), train_loss = 3.035, time/batch = 0.250\n",
            "50/638 (epoch 0), train_loss = 3.051, time/batch = 0.244\n",
            "51/638 (epoch 0), train_loss = 3.085, time/batch = 0.242\n",
            "52/638 (epoch 0), train_loss = 2.997, time/batch = 0.244\n",
            "53/638 (epoch 0), train_loss = 2.969, time/batch = 0.241\n",
            "54/638 (epoch 0), train_loss = 3.014, time/batch = 0.267\n",
            "55/638 (epoch 0), train_loss = 2.978, time/batch = 0.236\n",
            "56/638 (epoch 0), train_loss = 2.999, time/batch = 0.225\n",
            "57/638 (epoch 0), train_loss = 3.001, time/batch = 0.259\n",
            "58/638 (epoch 0), train_loss = 2.946, time/batch = 0.257\n",
            "59/638 (epoch 0), train_loss = 2.960, time/batch = 0.229\n",
            "60/638 (epoch 0), train_loss = 3.031, time/batch = 0.237\n",
            "61/638 (epoch 0), train_loss = 2.981, time/batch = 0.247\n",
            "62/638 (epoch 0), train_loss = 2.990, time/batch = 0.251\n",
            "63/638 (epoch 0), train_loss = 2.899, time/batch = 0.261\n",
            "64/638 (epoch 0), train_loss = 2.899, time/batch = 0.244\n",
            "65/638 (epoch 0), train_loss = 2.969, time/batch = 0.268\n",
            "66/638 (epoch 0), train_loss = 2.935, time/batch = 0.248\n",
            "67/638 (epoch 0), train_loss = 2.902, time/batch = 0.267\n",
            "68/638 (epoch 0), train_loss = 2.924, time/batch = 0.254\n",
            "69/638 (epoch 0), train_loss = 2.861, time/batch = 0.260\n",
            "70/638 (epoch 0), train_loss = 2.854, time/batch = 0.259\n",
            "71/638 (epoch 0), train_loss = 2.895, time/batch = 0.222\n",
            "72/638 (epoch 0), train_loss = 2.843, time/batch = 0.236\n",
            "73/638 (epoch 0), train_loss = 2.855, time/batch = 0.224\n",
            "74/638 (epoch 0), train_loss = 2.822, time/batch = 0.256\n",
            "75/638 (epoch 0), train_loss = 2.790, time/batch = 0.258\n",
            "76/638 (epoch 0), train_loss = 2.766, time/batch = 0.254\n",
            "77/638 (epoch 0), train_loss = 2.795, time/batch = 0.247\n",
            "78/638 (epoch 0), train_loss = 2.789, time/batch = 0.265\n",
            "79/638 (epoch 0), train_loss = 2.746, time/batch = 0.148\n",
            "80/638 (epoch 0), train_loss = 2.678, time/batch = 0.165\n",
            "81/638 (epoch 0), train_loss = 2.748, time/batch = 0.153\n",
            "82/638 (epoch 0), train_loss = 2.735, time/batch = 0.144\n",
            "83/638 (epoch 0), train_loss = 2.801, time/batch = 0.157\n",
            "84/638 (epoch 0), train_loss = 2.716, time/batch = 0.154\n",
            "85/638 (epoch 0), train_loss = 2.800, time/batch = 0.152\n",
            "86/638 (epoch 0), train_loss = 2.791, time/batch = 0.145\n",
            "87/638 (epoch 0), train_loss = 2.655, time/batch = 0.169\n",
            "88/638 (epoch 0), train_loss = 2.624, time/batch = 0.157\n",
            "89/638 (epoch 0), train_loss = 2.642, time/batch = 0.142\n",
            "90/638 (epoch 0), train_loss = 2.611, time/batch = 0.147\n",
            "91/638 (epoch 0), train_loss = 2.601, time/batch = 0.162\n",
            "92/638 (epoch 0), train_loss = 2.576, time/batch = 0.156\n",
            "93/638 (epoch 0), train_loss = 2.590, time/batch = 0.154\n",
            "94/638 (epoch 0), train_loss = 2.557, time/batch = 0.164\n",
            "95/638 (epoch 0), train_loss = 2.630, time/batch = 0.255\n",
            "96/638 (epoch 0), train_loss = 2.648, time/batch = 0.282\n",
            "97/638 (epoch 0), train_loss = 2.546, time/batch = 0.257\n",
            "98/638 (epoch 0), train_loss = 2.608, time/batch = 0.264\n",
            "99/638 (epoch 0), train_loss = 2.631, time/batch = 0.258\n",
            "100/638 (epoch 0), train_loss = 2.556, time/batch = 0.244\n",
            "101/638 (epoch 0), train_loss = 2.512, time/batch = 0.257\n",
            "102/638 (epoch 0), train_loss = 2.536, time/batch = 0.252\n",
            "103/638 (epoch 0), train_loss = 2.582, time/batch = 0.257\n",
            "104/638 (epoch 0), train_loss = 2.542, time/batch = 0.252\n",
            "105/638 (epoch 0), train_loss = 2.581, time/batch = 0.259\n",
            "106/638 (epoch 0), train_loss = 2.523, time/batch = 0.240\n",
            "107/638 (epoch 0), train_loss = 2.531, time/batch = 0.240\n",
            "108/638 (epoch 0), train_loss = 2.508, time/batch = 0.264\n",
            "109/638 (epoch 0), train_loss = 2.554, time/batch = 0.254\n",
            "110/638 (epoch 0), train_loss = 2.565, time/batch = 0.288\n",
            "111/638 (epoch 0), train_loss = 2.520, time/batch = 0.282\n",
            "112/638 (epoch 0), train_loss = 2.464, time/batch = 0.253\n",
            "113/638 (epoch 0), train_loss = 2.474, time/batch = 0.243\n",
            "114/638 (epoch 0), train_loss = 2.551, time/batch = 0.249\n",
            "115/638 (epoch 0), train_loss = 2.473, time/batch = 0.227\n",
            "116/638 (epoch 0), train_loss = 2.495, time/batch = 0.264\n",
            "117/638 (epoch 0), train_loss = 2.486, time/batch = 0.228\n",
            "118/638 (epoch 0), train_loss = 2.459, time/batch = 0.257\n",
            "119/638 (epoch 0), train_loss = 2.559, time/batch = 0.248\n",
            "120/638 (epoch 0), train_loss = 2.465, time/batch = 0.260\n",
            "121/638 (epoch 0), train_loss = 2.449, time/batch = 0.253\n",
            "122/638 (epoch 0), train_loss = 2.419, time/batch = 0.263\n",
            "123/638 (epoch 0), train_loss = 2.452, time/batch = 0.240\n",
            "124/638 (epoch 0), train_loss = 2.463, time/batch = 0.275\n",
            "125/638 (epoch 0), train_loss = 2.398, time/batch = 0.253\n",
            "126/638 (epoch 0), train_loss = 2.543, time/batch = 0.253\n",
            "127/638 (epoch 0), train_loss = 2.439, time/batch = 0.266\n",
            "128/638 (epoch 0), train_loss = 2.492, time/batch = 0.274\n",
            "129/638 (epoch 0), train_loss = 2.437, time/batch = 0.272\n",
            "130/638 (epoch 0), train_loss = 2.389, time/batch = 0.254\n",
            "131/638 (epoch 0), train_loss = 2.403, time/batch = 0.267\n",
            "132/638 (epoch 0), train_loss = 2.510, time/batch = 0.269\n",
            "133/638 (epoch 0), train_loss = 2.546, time/batch = 0.293\n",
            "134/638 (epoch 0), train_loss = 2.408, time/batch = 0.239\n",
            "135/638 (epoch 0), train_loss = 2.488, time/batch = 0.256\n",
            "136/638 (epoch 0), train_loss = 2.504, time/batch = 0.262\n",
            "137/638 (epoch 0), train_loss = 2.415, time/batch = 0.273\n",
            "138/638 (epoch 0), train_loss = 2.389, time/batch = 0.263\n",
            "139/638 (epoch 0), train_loss = 2.469, time/batch = 0.276\n",
            "140/638 (epoch 0), train_loss = 2.458, time/batch = 0.241\n",
            "141/638 (epoch 0), train_loss = 2.446, time/batch = 0.250\n",
            "142/638 (epoch 0), train_loss = 2.446, time/batch = 0.251\n",
            "143/638 (epoch 0), train_loss = 2.492, time/batch = 0.261\n",
            "144/638 (epoch 0), train_loss = 2.442, time/batch = 0.260\n",
            "145/638 (epoch 0), train_loss = 2.415, time/batch = 0.248\n",
            "146/638 (epoch 0), train_loss = 2.420, time/batch = 0.241\n",
            "147/638 (epoch 0), train_loss = 2.309, time/batch = 0.248\n",
            "148/638 (epoch 0), train_loss = 2.366, time/batch = 0.238\n",
            "149/638 (epoch 0), train_loss = 2.466, time/batch = 0.258\n",
            "150/638 (epoch 0), train_loss = 2.471, time/batch = 0.256\n",
            "151/638 (epoch 0), train_loss = 2.393, time/batch = 0.245\n",
            "152/638 (epoch 0), train_loss = 2.473, time/batch = 0.262\n",
            "153/638 (epoch 0), train_loss = 2.359, time/batch = 0.243\n",
            "154/638 (epoch 0), train_loss = 2.318, time/batch = 0.279\n",
            "155/638 (epoch 0), train_loss = 2.358, time/batch = 0.259\n",
            "156/638 (epoch 0), train_loss = 2.345, time/batch = 0.258\n",
            "157/638 (epoch 0), train_loss = 2.342, time/batch = 0.249\n",
            "158/638 (epoch 0), train_loss = 2.410, time/batch = 0.262\n",
            "159/638 (epoch 0), train_loss = 2.438, time/batch = 0.259\n",
            "160/638 (epoch 0), train_loss = 2.361, time/batch = 0.275\n",
            "161/638 (epoch 0), train_loss = 2.362, time/batch = 0.245\n",
            "162/638 (epoch 0), train_loss = 2.394, time/batch = 0.247\n",
            "163/638 (epoch 0), train_loss = 2.414, time/batch = 0.247\n",
            "164/638 (epoch 0), train_loss = 2.382, time/batch = 0.247\n",
            "165/638 (epoch 0), train_loss = 2.389, time/batch = 0.237\n",
            "166/638 (epoch 0), train_loss = 2.486, time/batch = 0.256\n",
            "167/638 (epoch 0), train_loss = 2.367, time/batch = 0.251\n",
            "168/638 (epoch 0), train_loss = 2.393, time/batch = 0.246\n",
            "169/638 (epoch 0), train_loss = 2.422, time/batch = 0.256\n",
            "170/638 (epoch 0), train_loss = 2.330, time/batch = 0.244\n",
            "171/638 (epoch 0), train_loss = 2.403, time/batch = 0.244\n",
            "172/638 (epoch 0), train_loss = 2.364, time/batch = 0.245\n",
            "173/638 (epoch 0), train_loss = 2.349, time/batch = 0.248\n",
            "174/638 (epoch 0), train_loss = 2.296, time/batch = 0.248\n",
            "175/638 (epoch 0), train_loss = 2.253, time/batch = 0.237\n",
            "176/638 (epoch 0), train_loss = 2.354, time/batch = 0.244\n",
            "177/638 (epoch 0), train_loss = 2.477, time/batch = 0.257\n",
            "178/638 (epoch 0), train_loss = 2.292, time/batch = 0.253\n",
            "179/638 (epoch 0), train_loss = 2.312, time/batch = 0.248\n",
            "180/638 (epoch 0), train_loss = 2.291, time/batch = 0.249\n",
            "181/638 (epoch 0), train_loss = 2.344, time/batch = 0.237\n",
            "182/638 (epoch 0), train_loss = 2.386, time/batch = 0.149\n",
            "183/638 (epoch 0), train_loss = 2.287, time/batch = 0.148\n",
            "184/638 (epoch 0), train_loss = 2.309, time/batch = 0.151\n",
            "185/638 (epoch 0), train_loss = 2.333, time/batch = 0.155\n",
            "186/638 (epoch 0), train_loss = 2.343, time/batch = 0.166\n",
            "187/638 (epoch 0), train_loss = 2.302, time/batch = 0.154\n",
            "188/638 (epoch 0), train_loss = 2.287, time/batch = 0.144\n",
            "189/638 (epoch 0), train_loss = 2.351, time/batch = 0.158\n",
            "190/638 (epoch 0), train_loss = 2.378, time/batch = 0.143\n",
            "191/638 (epoch 0), train_loss = 2.246, time/batch = 0.162\n",
            "192/638 (epoch 0), train_loss = 2.294, time/batch = 0.148\n",
            "193/638 (epoch 0), train_loss = 2.369, time/batch = 0.172\n",
            "194/638 (epoch 0), train_loss = 2.286, time/batch = 0.152\n",
            "195/638 (epoch 0), train_loss = 2.286, time/batch = 0.145\n",
            "196/638 (epoch 0), train_loss = 2.304, time/batch = 0.160\n",
            "197/638 (epoch 0), train_loss = 2.287, time/batch = 0.166\n",
            "198/638 (epoch 0), train_loss = 2.289, time/batch = 0.160\n",
            "199/638 (epoch 0), train_loss = 2.315, time/batch = 0.162\n",
            "200/638 (epoch 0), train_loss = 2.262, time/batch = 0.158\n",
            "201/638 (epoch 0), train_loss = 2.251, time/batch = 0.151\n",
            "202/638 (epoch 0), train_loss = 2.285, time/batch = 0.153\n",
            "203/638 (epoch 0), train_loss = 2.273, time/batch = 0.147\n",
            "204/638 (epoch 0), train_loss = 2.247, time/batch = 0.156\n",
            "205/638 (epoch 0), train_loss = 2.262, time/batch = 0.152\n",
            "206/638 (epoch 0), train_loss = 2.263, time/batch = 0.154\n",
            "207/638 (epoch 0), train_loss = 2.264, time/batch = 0.151\n",
            "208/638 (epoch 0), train_loss = 2.320, time/batch = 0.158\n",
            "209/638 (epoch 0), train_loss = 2.270, time/batch = 0.148\n",
            "210/638 (epoch 0), train_loss = 2.328, time/batch = 0.152\n",
            "211/638 (epoch 0), train_loss = 2.267, time/batch = 0.153\n",
            "212/638 (epoch 0), train_loss = 2.336, time/batch = 0.174\n",
            "213/638 (epoch 0), train_loss = 2.191, time/batch = 0.150\n",
            "214/638 (epoch 0), train_loss = 2.215, time/batch = 0.147\n",
            "215/638 (epoch 0), train_loss = 2.252, time/batch = 0.160\n",
            "216/638 (epoch 0), train_loss = 2.283, time/batch = 0.157\n",
            "217/638 (epoch 0), train_loss = 2.262, time/batch = 0.147\n",
            "218/638 (epoch 0), train_loss = 2.298, time/batch = 0.158\n",
            "219/638 (epoch 0), train_loss = 2.285, time/batch = 0.166\n",
            "220/638 (epoch 0), train_loss = 2.273, time/batch = 0.155\n",
            "221/638 (epoch 0), train_loss = 2.246, time/batch = 0.144\n",
            "222/638 (epoch 0), train_loss = 2.319, time/batch = 0.152\n",
            "223/638 (epoch 0), train_loss = 2.327, time/batch = 0.149\n",
            "224/638 (epoch 0), train_loss = 2.289, time/batch = 0.150\n",
            "225/638 (epoch 0), train_loss = 2.206, time/batch = 0.156\n",
            "226/638 (epoch 0), train_loss = 2.261, time/batch = 0.167\n",
            "227/638 (epoch 0), train_loss = 2.205, time/batch = 0.151\n",
            "228/638 (epoch 0), train_loss = 2.229, time/batch = 0.160\n",
            "229/638 (epoch 0), train_loss = 2.244, time/batch = 0.164\n",
            "230/638 (epoch 0), train_loss = 2.261, time/batch = 0.162\n",
            "231/638 (epoch 0), train_loss = 2.236, time/batch = 0.147\n",
            "232/638 (epoch 0), train_loss = 2.241, time/batch = 0.169\n",
            "233/638 (epoch 0), train_loss = 2.219, time/batch = 0.168\n",
            "234/638 (epoch 0), train_loss = 2.328, time/batch = 0.145\n",
            "235/638 (epoch 0), train_loss = 2.225, time/batch = 0.155\n",
            "236/638 (epoch 0), train_loss = 2.254, time/batch = 0.164\n",
            "237/638 (epoch 0), train_loss = 2.249, time/batch = 0.149\n",
            "238/638 (epoch 0), train_loss = 2.231, time/batch = 0.159\n",
            "239/638 (epoch 0), train_loss = 2.214, time/batch = 0.162\n",
            "240/638 (epoch 0), train_loss = 2.196, time/batch = 0.158\n",
            "241/638 (epoch 0), train_loss = 2.226, time/batch = 0.164\n",
            "242/638 (epoch 0), train_loss = 2.252, time/batch = 0.154\n",
            "243/638 (epoch 0), train_loss = 2.220, time/batch = 0.152\n",
            "244/638 (epoch 0), train_loss = 2.187, time/batch = 0.151\n",
            "245/638 (epoch 0), train_loss = 2.203, time/batch = 0.159\n",
            "246/638 (epoch 0), train_loss = 2.287, time/batch = 0.215\n",
            "247/638 (epoch 0), train_loss = 2.263, time/batch = 0.247\n",
            "248/638 (epoch 0), train_loss = 2.166, time/batch = 0.253\n",
            "249/638 (epoch 0), train_loss = 2.199, time/batch = 0.255\n",
            "250/638 (epoch 0), train_loss = 2.198, time/batch = 0.255\n",
            "251/638 (epoch 0), train_loss = 2.175, time/batch = 0.236\n",
            "252/638 (epoch 0), train_loss = 2.178, time/batch = 0.244\n",
            "253/638 (epoch 0), train_loss = 2.179, time/batch = 0.268\n",
            "254/638 (epoch 0), train_loss = 2.288, time/batch = 0.244\n",
            "255/638 (epoch 0), train_loss = 2.261, time/batch = 0.240\n",
            "256/638 (epoch 0), train_loss = 2.162, time/batch = 0.226\n",
            "257/638 (epoch 0), train_loss = 2.166, time/batch = 0.250\n",
            "258/638 (epoch 0), train_loss = 2.228, time/batch = 0.245\n",
            "259/638 (epoch 0), train_loss = 2.178, time/batch = 0.250\n",
            "260/638 (epoch 0), train_loss = 2.176, time/batch = 0.258\n",
            "261/638 (epoch 0), train_loss = 2.171, time/batch = 0.249\n",
            "262/638 (epoch 0), train_loss = 2.239, time/batch = 0.254\n",
            "263/638 (epoch 0), train_loss = 2.194, time/batch = 0.248\n",
            "264/638 (epoch 0), train_loss = 2.288, time/batch = 0.252\n",
            "265/638 (epoch 0), train_loss = 2.180, time/batch = 0.251\n",
            "266/638 (epoch 0), train_loss = 2.198, time/batch = 0.262\n",
            "267/638 (epoch 0), train_loss = 2.224, time/batch = 0.254\n",
            "268/638 (epoch 0), train_loss = 2.212, time/batch = 0.258\n",
            "269/638 (epoch 0), train_loss = 2.187, time/batch = 0.263\n",
            "270/638 (epoch 0), train_loss = 2.196, time/batch = 0.268\n",
            "271/638 (epoch 0), train_loss = 2.178, time/batch = 0.277\n",
            "272/638 (epoch 0), train_loss = 2.167, time/batch = 0.261\n",
            "273/638 (epoch 0), train_loss = 2.152, time/batch = 0.261\n",
            "274/638 (epoch 0), train_loss = 2.157, time/batch = 0.239\n",
            "275/638 (epoch 0), train_loss = 2.184, time/batch = 0.257\n",
            "276/638 (epoch 0), train_loss = 2.197, time/batch = 0.257\n",
            "277/638 (epoch 0), train_loss = 2.134, time/batch = 0.256\n",
            "278/638 (epoch 0), train_loss = 2.213, time/batch = 0.253\n",
            "279/638 (epoch 0), train_loss = 2.231, time/batch = 0.247\n",
            "280/638 (epoch 0), train_loss = 2.209, time/batch = 0.241\n",
            "281/638 (epoch 0), train_loss = 2.171, time/batch = 0.257\n",
            "282/638 (epoch 0), train_loss = 2.139, time/batch = 0.260\n",
            "283/638 (epoch 0), train_loss = 2.104, time/batch = 0.266\n",
            "284/638 (epoch 0), train_loss = 2.155, time/batch = 0.247\n",
            "285/638 (epoch 0), train_loss = 2.081, time/batch = 0.246\n",
            "286/638 (epoch 0), train_loss = 2.181, time/batch = 0.252\n",
            "287/638 (epoch 0), train_loss = 2.191, time/batch = 0.255\n",
            "288/638 (epoch 0), train_loss = 2.129, time/batch = 0.261\n",
            "289/638 (epoch 0), train_loss = 2.063, time/batch = 0.244\n",
            "290/638 (epoch 0), train_loss = 2.162, time/batch = 0.266\n",
            "291/638 (epoch 0), train_loss = 2.150, time/batch = 0.294\n",
            "292/638 (epoch 0), train_loss = 2.102, time/batch = 0.257\n",
            "293/638 (epoch 0), train_loss = 2.141, time/batch = 0.262\n",
            "294/638 (epoch 0), train_loss = 2.197, time/batch = 0.271\n",
            "295/638 (epoch 0), train_loss = 2.128, time/batch = 0.233\n",
            "296/638 (epoch 0), train_loss = 2.089, time/batch = 0.258\n",
            "297/638 (epoch 0), train_loss = 2.174, time/batch = 0.159\n",
            "298/638 (epoch 0), train_loss = 2.130, time/batch = 0.150\n",
            "299/638 (epoch 0), train_loss = 2.179, time/batch = 0.157\n",
            "300/638 (epoch 0), train_loss = 2.132, time/batch = 0.157\n",
            "301/638 (epoch 0), train_loss = 2.238, time/batch = 0.141\n",
            "302/638 (epoch 0), train_loss = 2.110, time/batch = 0.154\n",
            "303/638 (epoch 0), train_loss = 2.132, time/batch = 0.154\n",
            "304/638 (epoch 0), train_loss = 2.076, time/batch = 0.167\n",
            "305/638 (epoch 0), train_loss = 2.092, time/batch = 0.151\n",
            "306/638 (epoch 0), train_loss = 2.123, time/batch = 0.154\n",
            "307/638 (epoch 0), train_loss = 2.095, time/batch = 0.161\n",
            "308/638 (epoch 0), train_loss = 2.111, time/batch = 0.146\n",
            "309/638 (epoch 0), train_loss = 2.074, time/batch = 0.176\n",
            "310/638 (epoch 0), train_loss = 2.090, time/batch = 0.164\n",
            "311/638 (epoch 0), train_loss = 2.133, time/batch = 0.150\n",
            "312/638 (epoch 0), train_loss = 2.080, time/batch = 0.146\n",
            "313/638 (epoch 0), train_loss = 2.129, time/batch = 0.165\n",
            "314/638 (epoch 0), train_loss = 2.129, time/batch = 0.155\n",
            "315/638 (epoch 0), train_loss = 2.106, time/batch = 0.150\n",
            "316/638 (epoch 0), train_loss = 2.072, time/batch = 0.154\n",
            "317/638 (epoch 0), train_loss = 2.084, time/batch = 0.164\n",
            "318/638 (epoch 0), train_loss = 2.090, time/batch = 0.159\n",
            "319/638 (epoch 1), train_loss = 2.288, time/batch = 0.175\n",
            "320/638 (epoch 1), train_loss = 2.177, time/batch = 0.152\n",
            "321/638 (epoch 1), train_loss = 2.136, time/batch = 0.150\n",
            "322/638 (epoch 1), train_loss = 2.086, time/batch = 0.155\n",
            "323/638 (epoch 1), train_loss = 2.062, time/batch = 0.154\n",
            "324/638 (epoch 1), train_loss = 2.051, time/batch = 0.153\n",
            "325/638 (epoch 1), train_loss = 2.074, time/batch = 0.162\n",
            "326/638 (epoch 1), train_loss = 2.084, time/batch = 0.162\n",
            "327/638 (epoch 1), train_loss = 2.115, time/batch = 0.153\n",
            "328/638 (epoch 1), train_loss = 2.088, time/batch = 0.156\n",
            "329/638 (epoch 1), train_loss = 2.052, time/batch = 0.157\n",
            "330/638 (epoch 1), train_loss = 2.094, time/batch = 0.162\n",
            "331/638 (epoch 1), train_loss = 2.098, time/batch = 0.152\n",
            "332/638 (epoch 1), train_loss = 2.102, time/batch = 0.161\n",
            "333/638 (epoch 1), train_loss = 2.133, time/batch = 0.150\n",
            "334/638 (epoch 1), train_loss = 2.134, time/batch = 0.149\n",
            "335/638 (epoch 1), train_loss = 2.134, time/batch = 0.164\n",
            "336/638 (epoch 1), train_loss = 2.057, time/batch = 0.156\n",
            "337/638 (epoch 1), train_loss = 2.028, time/batch = 0.155\n",
            "338/638 (epoch 1), train_loss = 2.039, time/batch = 0.156\n",
            "339/638 (epoch 1), train_loss = 2.041, time/batch = 0.154\n",
            "340/638 (epoch 1), train_loss = 2.199, time/batch = 0.158\n",
            "341/638 (epoch 1), train_loss = 2.068, time/batch = 0.146\n",
            "342/638 (epoch 1), train_loss = 2.052, time/batch = 0.153\n",
            "343/638 (epoch 1), train_loss = 2.130, time/batch = 0.151\n",
            "344/638 (epoch 1), train_loss = 2.050, time/batch = 0.149\n",
            "345/638 (epoch 1), train_loss = 2.081, time/batch = 0.161\n",
            "346/638 (epoch 1), train_loss = 2.081, time/batch = 0.154\n",
            "347/638 (epoch 1), train_loss = 2.096, time/batch = 0.154\n",
            "348/638 (epoch 1), train_loss = 2.041, time/batch = 0.165\n",
            "349/638 (epoch 1), train_loss = 1.993, time/batch = 0.161\n",
            "350/638 (epoch 1), train_loss = 2.064, time/batch = 0.162\n",
            "351/638 (epoch 1), train_loss = 2.117, time/batch = 0.152\n",
            "352/638 (epoch 1), train_loss = 2.103, time/batch = 0.163\n",
            "353/638 (epoch 1), train_loss = 2.072, time/batch = 0.153\n",
            "354/638 (epoch 1), train_loss = 2.090, time/batch = 0.161\n",
            "355/638 (epoch 1), train_loss = 2.053, time/batch = 0.162\n",
            "356/638 (epoch 1), train_loss = 2.042, time/batch = 0.152\n",
            "357/638 (epoch 1), train_loss = 2.048, time/batch = 0.141\n",
            "358/638 (epoch 1), train_loss = 2.045, time/batch = 0.151\n",
            "359/638 (epoch 1), train_loss = 2.077, time/batch = 0.163\n",
            "360/638 (epoch 1), train_loss = 2.039, time/batch = 0.262\n",
            "361/638 (epoch 1), train_loss = 2.040, time/batch = 0.259\n",
            "362/638 (epoch 1), train_loss = 2.036, time/batch = 0.257\n",
            "363/638 (epoch 1), train_loss = 2.024, time/batch = 0.266\n",
            "364/638 (epoch 1), train_loss = 2.023, time/batch = 0.254\n",
            "365/638 (epoch 1), train_loss = 1.987, time/batch = 0.252\n",
            "366/638 (epoch 1), train_loss = 2.066, time/batch = 0.250\n",
            "367/638 (epoch 1), train_loss = 2.050, time/batch = 0.243\n",
            "368/638 (epoch 1), train_loss = 2.065, time/batch = 0.244\n",
            "369/638 (epoch 1), train_loss = 2.044, time/batch = 0.245\n",
            "370/638 (epoch 1), train_loss = 2.109, time/batch = 0.240\n",
            "371/638 (epoch 1), train_loss = 1.974, time/batch = 0.266\n",
            "372/638 (epoch 1), train_loss = 2.019, time/batch = 0.260\n",
            "373/638 (epoch 1), train_loss = 1.965, time/batch = 0.290\n",
            "374/638 (epoch 1), train_loss = 1.997, time/batch = 0.255\n",
            "375/638 (epoch 1), train_loss = 2.019, time/batch = 0.249\n",
            "376/638 (epoch 1), train_loss = 2.050, time/batch = 0.231\n",
            "377/638 (epoch 1), train_loss = 2.064, time/batch = 0.259\n",
            "378/638 (epoch 1), train_loss = 2.030, time/batch = 0.256\n",
            "379/638 (epoch 1), train_loss = 2.076, time/batch = 0.259\n",
            "380/638 (epoch 1), train_loss = 2.004, time/batch = 0.247\n",
            "381/638 (epoch 1), train_loss = 2.063, time/batch = 0.246\n",
            "382/638 (epoch 1), train_loss = 1.973, time/batch = 0.251\n",
            "383/638 (epoch 1), train_loss = 2.001, time/batch = 0.240\n",
            "384/638 (epoch 1), train_loss = 2.009, time/batch = 0.239\n",
            "385/638 (epoch 1), train_loss = 2.065, time/batch = 0.252\n",
            "386/638 (epoch 1), train_loss = 2.054, time/batch = 0.247\n",
            "387/638 (epoch 1), train_loss = 2.032, time/batch = 0.240\n",
            "388/638 (epoch 1), train_loss = 2.016, time/batch = 0.251\n",
            "389/638 (epoch 1), train_loss = 2.054, time/batch = 0.262\n",
            "390/638 (epoch 1), train_loss = 2.053, time/batch = 0.235\n",
            "391/638 (epoch 1), train_loss = 2.030, time/batch = 0.237\n",
            "392/638 (epoch 1), train_loss = 2.077, time/batch = 0.228\n",
            "393/638 (epoch 1), train_loss = 2.022, time/batch = 0.270\n",
            "394/638 (epoch 1), train_loss = 1.976, time/batch = 0.262\n",
            "395/638 (epoch 1), train_loss = 1.993, time/batch = 0.241\n",
            "396/638 (epoch 1), train_loss = 2.030, time/batch = 0.264\n",
            "397/638 (epoch 1), train_loss = 2.032, time/batch = 0.262\n",
            "398/638 (epoch 1), train_loss = 1.984, time/batch = 0.240\n",
            "399/638 (epoch 1), train_loss = 2.008, time/batch = 0.250\n",
            "400/638 (epoch 1), train_loss = 2.055, time/batch = 0.243\n",
            "401/638 (epoch 1), train_loss = 1.980, time/batch = 0.254\n",
            "402/638 (epoch 1), train_loss = 2.059, time/batch = 0.260\n",
            "403/638 (epoch 1), train_loss = 2.021, time/batch = 0.256\n",
            "404/638 (epoch 1), train_loss = 2.072, time/batch = 0.246\n",
            "405/638 (epoch 1), train_loss = 2.089, time/batch = 0.259\n",
            "406/638 (epoch 1), train_loss = 1.977, time/batch = 0.258\n",
            "407/638 (epoch 1), train_loss = 1.988, time/batch = 0.257\n",
            "408/638 (epoch 1), train_loss = 2.002, time/batch = 0.243\n",
            "409/638 (epoch 1), train_loss = 1.956, time/batch = 0.273\n",
            "410/638 (epoch 1), train_loss = 1.977, time/batch = 0.191\n",
            "411/638 (epoch 1), train_loss = 1.977, time/batch = 0.150\n",
            "412/638 (epoch 1), train_loss = 1.981, time/batch = 0.159\n",
            "413/638 (epoch 1), train_loss = 1.998, time/batch = 0.152\n",
            "414/638 (epoch 1), train_loss = 2.042, time/batch = 0.158\n",
            "415/638 (epoch 1), train_loss = 1.960, time/batch = 0.164\n",
            "416/638 (epoch 1), train_loss = 1.980, time/batch = 0.156\n",
            "417/638 (epoch 1), train_loss = 2.037, time/batch = 0.154\n",
            "418/638 (epoch 1), train_loss = 1.979, time/batch = 0.143\n",
            "419/638 (epoch 1), train_loss = 1.956, time/batch = 0.145\n",
            "420/638 (epoch 1), train_loss = 1.966, time/batch = 0.155\n",
            "421/638 (epoch 1), train_loss = 1.972, time/batch = 0.172\n",
            "422/638 (epoch 1), train_loss = 2.012, time/batch = 0.153\n",
            "423/638 (epoch 1), train_loss = 1.932, time/batch = 0.168\n",
            "424/638 (epoch 1), train_loss = 1.975, time/batch = 0.154\n",
            "425/638 (epoch 1), train_loss = 1.949, time/batch = 0.159\n",
            "426/638 (epoch 1), train_loss = 2.018, time/batch = 0.157\n",
            "427/638 (epoch 1), train_loss = 1.999, time/batch = 0.151\n",
            "428/638 (epoch 1), train_loss = 1.992, time/batch = 0.156\n",
            "429/638 (epoch 1), train_loss = 2.028, time/batch = 0.148\n",
            "430/638 (epoch 1), train_loss = 1.999, time/batch = 0.156\n",
            "431/638 (epoch 1), train_loss = 1.992, time/batch = 0.140\n",
            "432/638 (epoch 1), train_loss = 1.975, time/batch = 0.163\n",
            "433/638 (epoch 1), train_loss = 2.009, time/batch = 0.166\n",
            "434/638 (epoch 1), train_loss = 1.968, time/batch = 0.174\n",
            "435/638 (epoch 1), train_loss = 1.922, time/batch = 0.152\n",
            "436/638 (epoch 1), train_loss = 1.967, time/batch = 0.146\n",
            "437/638 (epoch 1), train_loss = 1.942, time/batch = 0.144\n",
            "438/638 (epoch 1), train_loss = 2.020, time/batch = 0.143\n",
            "439/638 (epoch 1), train_loss = 1.934, time/batch = 0.154\n",
            "440/638 (epoch 1), train_loss = 1.977, time/batch = 0.148\n",
            "441/638 (epoch 1), train_loss = 1.946, time/batch = 0.161\n",
            "442/638 (epoch 1), train_loss = 1.968, time/batch = 0.147\n",
            "443/638 (epoch 1), train_loss = 1.962, time/batch = 0.147\n",
            "444/638 (epoch 1), train_loss = 1.925, time/batch = 0.148\n",
            "445/638 (epoch 1), train_loss = 2.052, time/batch = 0.150\n",
            "446/638 (epoch 1), train_loss = 1.916, time/batch = 0.144\n",
            "447/638 (epoch 1), train_loss = 1.969, time/batch = 0.142\n",
            "448/638 (epoch 1), train_loss = 2.001, time/batch = 0.158\n",
            "449/638 (epoch 1), train_loss = 1.899, time/batch = 0.151\n",
            "450/638 (epoch 1), train_loss = 1.957, time/batch = 0.159\n",
            "451/638 (epoch 1), train_loss = 2.015, time/batch = 0.150\n",
            "452/638 (epoch 1), train_loss = 2.010, time/batch = 0.164\n",
            "453/638 (epoch 1), train_loss = 1.975, time/batch = 0.163\n",
            "454/638 (epoch 1), train_loss = 1.990, time/batch = 0.158\n",
            "455/638 (epoch 1), train_loss = 2.009, time/batch = 0.163\n",
            "456/638 (epoch 1), train_loss = 1.906, time/batch = 0.156\n",
            "457/638 (epoch 1), train_loss = 1.927, time/batch = 0.152\n",
            "458/638 (epoch 1), train_loss = 1.975, time/batch = 0.143\n",
            "459/638 (epoch 1), train_loss = 2.041, time/batch = 0.154\n",
            "460/638 (epoch 1), train_loss = 2.029, time/batch = 0.153\n",
            "461/638 (epoch 1), train_loss = 1.940, time/batch = 0.163\n",
            "462/638 (epoch 1), train_loss = 1.995, time/batch = 0.152\n",
            "463/638 (epoch 1), train_loss = 1.932, time/batch = 0.141\n",
            "464/638 (epoch 1), train_loss = 1.966, time/batch = 0.176\n",
            "465/638 (epoch 1), train_loss = 1.970, time/batch = 0.162\n",
            "466/638 (epoch 1), train_loss = 1.889, time/batch = 0.151\n",
            "467/638 (epoch 1), train_loss = 1.889, time/batch = 0.149\n",
            "468/638 (epoch 1), train_loss = 1.965, time/batch = 0.160\n",
            "469/638 (epoch 1), train_loss = 1.970, time/batch = 0.150\n",
            "470/638 (epoch 1), train_loss = 1.960, time/batch = 0.181\n",
            "471/638 (epoch 1), train_loss = 1.979, time/batch = 0.155\n",
            "472/638 (epoch 1), train_loss = 1.928, time/batch = 0.162\n",
            "473/638 (epoch 1), train_loss = 1.894, time/batch = 0.147\n",
            "474/638 (epoch 1), train_loss = 1.932, time/batch = 0.203\n",
            "475/638 (epoch 1), train_loss = 1.922, time/batch = 0.243\n",
            "476/638 (epoch 1), train_loss = 1.946, time/batch = 0.243\n",
            "477/638 (epoch 1), train_loss = 1.987, time/batch = 0.255\n",
            "478/638 (epoch 1), train_loss = 2.008, time/batch = 0.258\n",
            "479/638 (epoch 1), train_loss = 1.932, time/batch = 0.257\n",
            "480/638 (epoch 1), train_loss = 1.915, time/batch = 0.248\n",
            "481/638 (epoch 1), train_loss = 1.992, time/batch = 0.247\n",
            "482/638 (epoch 1), train_loss = 1.955, time/batch = 0.245\n",
            "483/638 (epoch 1), train_loss = 1.960, time/batch = 0.246\n",
            "484/638 (epoch 1), train_loss = 1.925, time/batch = 0.253\n",
            "485/638 (epoch 1), train_loss = 1.944, time/batch = 0.265\n",
            "486/638 (epoch 1), train_loss = 1.926, time/batch = 0.245\n",
            "487/638 (epoch 1), train_loss = 1.929, time/batch = 0.243\n",
            "488/638 (epoch 1), train_loss = 1.962, time/batch = 0.258\n",
            "489/638 (epoch 1), train_loss = 1.930, time/batch = 0.254\n",
            "490/638 (epoch 1), train_loss = 1.982, time/batch = 0.249\n",
            "491/638 (epoch 1), train_loss = 1.975, time/batch = 0.253\n",
            "492/638 (epoch 1), train_loss = 1.909, time/batch = 0.244\n",
            "493/638 (epoch 1), train_loss = 1.901, time/batch = 0.248\n",
            "494/638 (epoch 1), train_loss = 1.884, time/batch = 0.251\n",
            "495/638 (epoch 1), train_loss = 1.922, time/batch = 0.249\n",
            "496/638 (epoch 1), train_loss = 1.974, time/batch = 0.256\n",
            "497/638 (epoch 1), train_loss = 1.894, time/batch = 0.253\n",
            "498/638 (epoch 1), train_loss = 1.930, time/batch = 0.246\n",
            "499/638 (epoch 1), train_loss = 1.908, time/batch = 0.240\n",
            "500/638 (epoch 1), train_loss = 1.926, time/batch = 0.235\n",
            "501/638 (epoch 1), train_loss = 1.926, time/batch = 0.240\n",
            "502/638 (epoch 1), train_loss = 1.879, time/batch = 0.259\n",
            "503/638 (epoch 1), train_loss = 1.947, time/batch = 0.272\n",
            "504/638 (epoch 1), train_loss = 1.935, time/batch = 0.276\n",
            "505/638 (epoch 1), train_loss = 1.926, time/batch = 0.254\n",
            "506/638 (epoch 1), train_loss = 1.892, time/batch = 0.245\n",
            "507/638 (epoch 1), train_loss = 1.881, time/batch = 0.256\n",
            "508/638 (epoch 1), train_loss = 1.954, time/batch = 0.241\n",
            "509/638 (epoch 1), train_loss = 1.916, time/batch = 0.264\n",
            "510/638 (epoch 1), train_loss = 1.863, time/batch = 0.244\n",
            "511/638 (epoch 1), train_loss = 1.902, time/batch = 0.253\n",
            "512/638 (epoch 1), train_loss = 1.970, time/batch = 0.261\n",
            "513/638 (epoch 1), train_loss = 1.904, time/batch = 0.251\n",
            "514/638 (epoch 1), train_loss = 1.911, time/batch = 0.251\n",
            "515/638 (epoch 1), train_loss = 1.891, time/batch = 0.251\n",
            "516/638 (epoch 1), train_loss = 1.886, time/batch = 0.245\n",
            "517/638 (epoch 1), train_loss = 1.891, time/batch = 0.250\n",
            "518/638 (epoch 1), train_loss = 1.898, time/batch = 0.247\n",
            "519/638 (epoch 1), train_loss = 1.861, time/batch = 0.250\n",
            "520/638 (epoch 1), train_loss = 1.873, time/batch = 0.246\n",
            "521/638 (epoch 1), train_loss = 1.893, time/batch = 0.258\n",
            "522/638 (epoch 1), train_loss = 1.891, time/batch = 0.258\n",
            "523/638 (epoch 1), train_loss = 1.874, time/batch = 0.243\n",
            "524/638 (epoch 1), train_loss = 1.859, time/batch = 0.262\n",
            "525/638 (epoch 1), train_loss = 1.892, time/batch = 0.190\n",
            "526/638 (epoch 1), train_loss = 1.879, time/batch = 0.154\n",
            "527/638 (epoch 1), train_loss = 1.905, time/batch = 0.154\n",
            "528/638 (epoch 1), train_loss = 1.892, time/batch = 0.150\n",
            "529/638 (epoch 1), train_loss = 1.931, time/batch = 0.165\n",
            "530/638 (epoch 1), train_loss = 1.890, time/batch = 0.166\n",
            "531/638 (epoch 1), train_loss = 1.904, time/batch = 0.156\n",
            "532/638 (epoch 1), train_loss = 1.835, time/batch = 0.150\n",
            "533/638 (epoch 1), train_loss = 1.849, time/batch = 0.160\n",
            "534/638 (epoch 1), train_loss = 1.847, time/batch = 0.155\n",
            "535/638 (epoch 1), train_loss = 1.894, time/batch = 0.149\n",
            "536/638 (epoch 1), train_loss = 1.895, time/batch = 0.160\n",
            "537/638 (epoch 1), train_loss = 1.878, time/batch = 0.164\n",
            "538/638 (epoch 1), train_loss = 1.880, time/batch = 0.155\n",
            "539/638 (epoch 1), train_loss = 1.939, time/batch = 0.153\n",
            "540/638 (epoch 1), train_loss = 1.867, time/batch = 0.153\n",
            "541/638 (epoch 1), train_loss = 1.930, time/batch = 0.153\n",
            "542/638 (epoch 1), train_loss = 1.922, time/batch = 0.153\n",
            "543/638 (epoch 1), train_loss = 1.927, time/batch = 0.162\n",
            "544/638 (epoch 1), train_loss = 1.840, time/batch = 0.175\n",
            "545/638 (epoch 1), train_loss = 1.931, time/batch = 0.151\n",
            "546/638 (epoch 1), train_loss = 1.857, time/batch = 0.152\n",
            "547/638 (epoch 1), train_loss = 1.882, time/batch = 0.153\n",
            "548/638 (epoch 1), train_loss = 1.887, time/batch = 0.153\n",
            "549/638 (epoch 1), train_loss = 1.912, time/batch = 0.141\n",
            "550/638 (epoch 1), train_loss = 1.889, time/batch = 0.154\n",
            "551/638 (epoch 1), train_loss = 1.858, time/batch = 0.141\n",
            "552/638 (epoch 1), train_loss = 1.838, time/batch = 0.146\n",
            "553/638 (epoch 1), train_loss = 1.942, time/batch = 0.156\n",
            "554/638 (epoch 1), train_loss = 1.894, time/batch = 0.147\n",
            "555/638 (epoch 1), train_loss = 1.898, time/batch = 0.151\n",
            "556/638 (epoch 1), train_loss = 1.904, time/batch = 0.152\n",
            "557/638 (epoch 1), train_loss = 1.929, time/batch = 0.157\n",
            "558/638 (epoch 1), train_loss = 1.874, time/batch = 0.148\n",
            "559/638 (epoch 1), train_loss = 1.883, time/batch = 0.154\n",
            "560/638 (epoch 1), train_loss = 1.917, time/batch = 0.158\n",
            "561/638 (epoch 1), train_loss = 1.883, time/batch = 0.151\n",
            "562/638 (epoch 1), train_loss = 1.873, time/batch = 0.149\n",
            "563/638 (epoch 1), train_loss = 1.850, time/batch = 0.150\n",
            "564/638 (epoch 1), train_loss = 1.845, time/batch = 0.171\n",
            "565/638 (epoch 1), train_loss = 1.904, time/batch = 0.165\n",
            "566/638 (epoch 1), train_loss = 1.855, time/batch = 0.152\n",
            "567/638 (epoch 1), train_loss = 1.837, time/batch = 0.148\n",
            "568/638 (epoch 1), train_loss = 1.861, time/batch = 0.150\n",
            "569/638 (epoch 1), train_loss = 1.855, time/batch = 0.154\n",
            "570/638 (epoch 1), train_loss = 1.850, time/batch = 0.170\n",
            "571/638 (epoch 1), train_loss = 1.847, time/batch = 0.154\n",
            "572/638 (epoch 1), train_loss = 1.850, time/batch = 0.154\n",
            "573/638 (epoch 1), train_loss = 1.914, time/batch = 0.153\n",
            "574/638 (epoch 1), train_loss = 1.928, time/batch = 0.152\n",
            "575/638 (epoch 1), train_loss = 1.844, time/batch = 0.160\n",
            "576/638 (epoch 1), train_loss = 1.859, time/batch = 0.151\n",
            "577/638 (epoch 1), train_loss = 1.886, time/batch = 0.180\n",
            "578/638 (epoch 1), train_loss = 1.815, time/batch = 0.158\n",
            "579/638 (epoch 1), train_loss = 1.831, time/batch = 0.154\n",
            "580/638 (epoch 1), train_loss = 1.879, time/batch = 0.152\n",
            "581/638 (epoch 1), train_loss = 1.918, time/batch = 0.154\n",
            "582/638 (epoch 1), train_loss = 1.864, time/batch = 0.169\n",
            "583/638 (epoch 1), train_loss = 1.926, time/batch = 0.168\n",
            "584/638 (epoch 1), train_loss = 1.854, time/batch = 0.157\n",
            "585/638 (epoch 1), train_loss = 1.883, time/batch = 0.167\n",
            "586/638 (epoch 1), train_loss = 1.856, time/batch = 0.157\n",
            "587/638 (epoch 1), train_loss = 1.849, time/batch = 0.147\n",
            "588/638 (epoch 1), train_loss = 1.869, time/batch = 0.160\n",
            "589/638 (epoch 1), train_loss = 1.875, time/batch = 0.186\n",
            "590/638 (epoch 1), train_loss = 1.875, time/batch = 0.264\n",
            "591/638 (epoch 1), train_loss = 1.850, time/batch = 0.254\n",
            "592/638 (epoch 1), train_loss = 1.831, time/batch = 0.250\n",
            "593/638 (epoch 1), train_loss = 1.818, time/batch = 0.263\n",
            "594/638 (epoch 1), train_loss = 1.883, time/batch = 0.261\n",
            "595/638 (epoch 1), train_loss = 1.866, time/batch = 0.253\n",
            "596/638 (epoch 1), train_loss = 1.828, time/batch = 0.259\n",
            "597/638 (epoch 1), train_loss = 1.880, time/batch = 0.240\n",
            "598/638 (epoch 1), train_loss = 1.900, time/batch = 0.247\n",
            "599/638 (epoch 1), train_loss = 1.936, time/batch = 0.257\n",
            "600/638 (epoch 1), train_loss = 1.838, time/batch = 0.261\n",
            "601/638 (epoch 1), train_loss = 1.859, time/batch = 0.286\n",
            "602/638 (epoch 1), train_loss = 1.777, time/batch = 0.257\n",
            "603/638 (epoch 1), train_loss = 1.879, time/batch = 0.257\n",
            "604/638 (epoch 1), train_loss = 1.784, time/batch = 0.254\n",
            "605/638 (epoch 1), train_loss = 1.864, time/batch = 0.263\n",
            "606/638 (epoch 1), train_loss = 1.861, time/batch = 0.248\n",
            "607/638 (epoch 1), train_loss = 1.847, time/batch = 0.244\n",
            "608/638 (epoch 1), train_loss = 1.748, time/batch = 0.278\n",
            "609/638 (epoch 1), train_loss = 1.834, time/batch = 0.249\n",
            "610/638 (epoch 1), train_loss = 1.863, time/batch = 0.265\n",
            "611/638 (epoch 1), train_loss = 1.825, time/batch = 0.253\n",
            "612/638 (epoch 1), train_loss = 1.834, time/batch = 0.265\n",
            "613/638 (epoch 1), train_loss = 1.872, time/batch = 0.246\n",
            "614/638 (epoch 1), train_loss = 1.846, time/batch = 0.266\n",
            "615/638 (epoch 1), train_loss = 1.824, time/batch = 0.278\n",
            "616/638 (epoch 1), train_loss = 1.859, time/batch = 0.271\n",
            "617/638 (epoch 1), train_loss = 1.818, time/batch = 0.245\n",
            "618/638 (epoch 1), train_loss = 1.866, time/batch = 0.236\n",
            "619/638 (epoch 1), train_loss = 1.846, time/batch = 0.247\n",
            "620/638 (epoch 1), train_loss = 1.924, time/batch = 0.257\n",
            "621/638 (epoch 1), train_loss = 1.793, time/batch = 0.257\n",
            "622/638 (epoch 1), train_loss = 1.876, time/batch = 0.245\n",
            "623/638 (epoch 1), train_loss = 1.798, time/batch = 0.240\n",
            "624/638 (epoch 1), train_loss = 1.823, time/batch = 0.233\n",
            "625/638 (epoch 1), train_loss = 1.804, time/batch = 0.264\n",
            "626/638 (epoch 1), train_loss = 1.808, time/batch = 0.253\n",
            "627/638 (epoch 1), train_loss = 1.831, time/batch = 0.255\n",
            "628/638 (epoch 1), train_loss = 1.794, time/batch = 0.255\n",
            "629/638 (epoch 1), train_loss = 1.785, time/batch = 0.261\n",
            "630/638 (epoch 1), train_loss = 1.822, time/batch = 0.250\n",
            "631/638 (epoch 1), train_loss = 1.808, time/batch = 0.258\n",
            "632/638 (epoch 1), train_loss = 1.835, time/batch = 0.237\n",
            "633/638 (epoch 1), train_loss = 1.861, time/batch = 0.236\n",
            "634/638 (epoch 1), train_loss = 1.837, time/batch = 0.241\n",
            "635/638 (epoch 1), train_loss = 1.809, time/batch = 0.250\n",
            "636/638 (epoch 1), train_loss = 1.806, time/batch = 0.254\n",
            "637/638 (epoch 1), train_loss = 1.814, time/batch = 0.243\n",
            "Model saved to ./checkpoints/paulocoelho/paulocoelho!\n",
            "Converting model to ml5js: paulocoelho paulocoelho-637\n",
            "Done! The output model is in ./models\n",
            "Check https://ml5js.org/docs/training-lstm for more information.\n",
            "  adding: models/paulocoelho/ (stored 0%)\n",
            "  adding: models/paulocoelho/rnnlm_multi_rnn_cell_cell_0_basic_lstm_cell_bias (deflated 8%)\n",
            "  adding: models/paulocoelho/embedding (deflated 7%)\n",
            "  adding: models/paulocoelho/vocab.json (deflated 61%)\n",
            "  adding: models/paulocoelho/Variable (stored 0%)\n",
            "  adding: models/paulocoelho/rnnlm_softmax_b (stored 0%)\n",
            "  adding: models/paulocoelho/rnnlm_softmax_w (deflated 7%)\n",
            "  adding: models/paulocoelho/rnnlm_multi_rnn_cell_cell_1_basic_lstm_cell_kernel (deflated 7%)\n",
            "  adding: models/paulocoelho/rnnlm_multi_rnn_cell_cell_0_basic_lstm_cell_kernel (deflated 7%)\n",
            "  adding: models/paulocoelho/rnnlm_multi_rnn_cell_cell_1_basic_lstm_cell_bias (deflated 8%)\n",
            "  adding: models/paulocoelho/manifest.json (deflated 80%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}